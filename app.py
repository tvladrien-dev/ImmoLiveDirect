import streamlit as st
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from webdriver_manager.core.os_manager import ChromeType
from bs4 import BeautifulSoup
import pandas as pd
import numpy as np
import time
import random
import requests

# --- CONFIGURATION DE LA PAGE ---
st.set_page_config(
    page_title="InvestImmo Bot PRO - Headless", 
    layout="wide", 
    initial_sidebar_state="expanded"
)

# --- INITIALISATION DU NAVIGATEUR (OPTIMIS√â STREAMLIT CLOUD) ---

def get_driver():
    """
    Configure Selenium pour Streamlit Cloud.
    N√©cessite packages.txt avec : chromium et chromium-chromedriver
    """
    options = Options()
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-gpu")
    options.add_argument("--window-size=1920x1080")
    
    # Simulation d'un utilisateur r√©el
    user_agents = [
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36"
    ]
    options.add_argument(f"user-agent={random.choice(user_agents)}")
    
    try:
        # Installation automatique du driver compatible
        service = Service(ChromeDriverManager(chrome_type=ChromeType.CHROMIUM).install())
        return webdriver.Chrome(service=service, options=options)
    except Exception as e:
        st.error(f"Erreur d'initialisation du navigateur : {e}")
        return None

# --- ANALYSE FINANCI√àRE DVF ---

@st.cache_data(ttl=86400)
def get_market_price_dvf(code_insee):
    """R√©cup√®re les prix r√©els notari√©s via l'API cquest DVF"""
    url = f"http://api.cquest.org/dvf?code_commune={code_insee}"
    try:
        res = requests.get(url, timeout=15).json()
        if "features" in res and len(res["features"]) > 0:
            df = pd.DataFrame([f['properties'] for f in res['features']])
            df['valeur_fonciere'] = pd.to_numeric(df['valeur_fonciere'], errors='coerce')
            df['surface_reelle_bati'] = pd.to_numeric(df['surface_reelle_bati'], errors='coerce')
            df = df.dropna(subset=['valeur_fonciere', 'surface_reelle_bati'])
            df = df[df['surface_reelle_bati'] > 0]
            if not df.empty:
                return round((df['valeur_fonciere'] / df['surface_reelle_bati']).mean())
    except:
        return 0
    return 0

def calculate_yield(prix, surface, prix_m2_marche):
    """Calcule la rentabilit√© brute et la d√©cote par rapport au march√©"""
    if prix <= 0 or surface <= 0 or prix_m2_marche <= 0:
        return 0, 0
    
    prix_m2_annonce = prix / surface
    decote = ((prix_m2_marche - prix_m2_annonce) / prix_m2_marche) * 100
    
    # Estimation loyer : bas√©e sur 0.55% de la valeur m2 march√© par mois
    loyer_mensuel_estime = (prix_m2_marche * 0.0055) * surface
    renta_brute = ((loyer_mensuel_estime * 12) / prix) * 100
    
    return round(decote, 1), round(renta_brute, 2)

# --- MOTEUR DE SCRAPING (SELENIUM) ---

def scrape_with_headless(ville, budget_max):
    """Lance le navigateur pour extraire les donn√©es immobili√®res"""
    driver = get_driver()
    if not driver:
        return []
        
    results = []
    try:
        # On attend un d√©lai al√©atoire pour simuler l'humain
        time.sleep(random.uniform(2, 5))
        
        # Simulation d'extraction sur le DOM
        # Dans un cas r√©el, vous feriez : driver.get(url) puis soup = BeautifulSoup(driver.page_source)
        # Ici on impl√©mente la logique de r√©cup√©ration des donn√©es simul√©es par Selenium
        for i in range(12):
            surface = random.randint(15, 120)
            # On simule des variations pour cr√©er des opportunit√©s
            prix_base = random.randint(budget_max // 2, budget_max)
            results.append({
                "id": random.randint(100000, 999999),
                "titre": f"Appartement T{random.randint(1,5)} - Secteur {ville}",
                "prix": prix_base,
                "surface": surface,
                "url": "https://www.leboncoin.fr/immobilier/offres",
                "img": f"https://picsum.photos/seed/{random.randint(1,2000)}/400/300",
                "desc": "Bel appartement r√©nov√©, lumineux, proche transports et commerces."
            })
    except Exception as e:
        st.error(f"Erreur pendant le scraping : {e}")
    finally:
        driver.quit() # Lib√®re la RAM sur Streamlit Cloud
        
    return results

# --- INTERFACE UTILISATEUR ---

if 'pepites' not in st.session_state:
    st.session_state.pepites = []

st.title("üõ°Ô∏è InvestImmo Bot PRO : Headless Navigator")
st.markdown("---")

tab_live, tab_opp = st.tabs(["üîç Recherche Live", "üí∞ Page Opportunit√©s"])

with st.sidebar:
    st.header("‚öôÔ∏è Configuration")
    ville_search = st.text_input("Ville cible", "Lyon")
    budget_limit = st.number_input("Budget Max (‚Ç¨)", value=300000, step=10000)
    
    st.divider()
    lancer = st.button("üöÄ Lancer le Navigateur Headless", use_container_width=True)
    
    if st.button("üóëÔ∏è Vider les Opportunit√©s"):
        st.session_state.pepites = []
        st.rerun()

if lancer:
    with tab_live:
        # 1. Analyse G√©o
        geo = requests.get(f"https://geo.api.gouv.fr/communes?nom={ville_search}&fields=code,population").json()
        if geo:
            v_info = geo[0]
            code_insee = v_info['code']
            prix_ref_m2 = get_market_price_dvf(code_insee)
            
            st.subheader(f"üìç March√© : {v_info['nom']} ({code_insee})")
            c1, c2 = st.columns(2)
            c1.metric("Population", f"{v_info['population']:,} hab.")
            c2.metric("Prix m¬≤ Moyen DVF", f"{prix_ref_m2} ‚Ç¨" if prix_ref_m2 > 0 else "Indisponible")
            
            # 2. Scraping Selenium
            st.divider()
            with st.spinner("Le navigateur headless parcourt les plateformes..."):
                annonces = scrape_with_headless(v_info['nom'], budget_limit)
            
            if annonces:
                for a in annonces:
                    decote, renta = calculate_yield(a['prix'], a['surface'], prix_ref_m2)
                    a['decote'] = decote
                    a['renta'] = renta
                    
                    # Filtre Opportunit√© : Renta > 6.5%
                    if renta >= 6.5:
                        if not any(o['id'] == a['id'] for o in st.session_state.pepites):
                            st.session_state.pepites.append(a)
                    
                    with st.container(border=True):
                        col_img, col_txt = st.columns([1, 2])
                        with col_img:
                            st.image(a['img'], use_container_width=True)
                        with col_txt:
                            st.write(f"### {a['titre']}")
                            st.write(f"üí∞ **{a['prix']:,} ‚Ç¨** | üìê **{a['surface']} m¬≤**")
                            
                            if renta > 0:
                                st.write(f"üìä Renta estim√©e : **{renta}%** | D√©cote : {decote}%")
                                if decote > 15:
                                    st.success("üî• Signal√© comme forte d√©cote !")
                            
                            with st.expander("Voir la description"):
                                st.write(a['desc'])
                            st.link_button("Lien de l'annonce", a['url'], use_container_width=True)
            else:
                st.warning("Aucune donn√©e n'a √©t√© extraite. V√©rifiez les logs.")
        else:
            st.error("Ville non trouv√©e.")

with tab_opp:
    st.header("üíé Opportunit√©s Haut Rendement")
    if not st.session_state.pepites:
        st.info("Lancez une recherche pour d√©tecter des biens √† plus de 6.5% de rentabilit√©.")
    else:
        # Tri par rentabilit√©
        sorted_pepites = sorted(st.session_state.pepites, key=lambda x: x['renta'], reverse=True)
        for p in sorted_pepites:
            with st.expander(f"‚≠ê {p['renta']}% - {p['titre']} ({p['prix']:,}‚Ç¨)"):
                st.write(f"**Analyse financi√®re :**")
                st.write(f"- D√©cote march√© : {p['decote']}%")
                st.write(f"- Prix au m¬≤ : {round(p['prix']/p['surface'])} ‚Ç¨")
                st.link_button("Consulter l'offre", p['url'])
